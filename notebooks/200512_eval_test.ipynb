{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data \n",
    "dfp = '/home/jovyan/work/ngr4/data/ed_data/final200427/final_4_27'\n",
    "pdfp = '/home/jovyan/work/ngr4/data/processed/'\n",
    "pfp = '/home/jovyan/work/ngr4/results/'\n",
    "\n",
    "X_test = pd.read_csv(os.path.join(pdfp,'X_test.csv'),index_col=0)\n",
    "y_test = pd.read_csv(os.path.join(pdfp,'y_test.csv'),index_col=0)\n",
    "X_test_cci = pd.read_csv(os.path.join(pdfp,'X_test_cci.csv'),index_col=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcsi(df):\n",
    "    \"\"\"Calcualate quick-CSI and return score for training.\n",
    "    Arguments:\n",
    "        df (pd.DataFrame): can be within cv-fold\n",
    "    \"\"\"\n",
    "    # impute\n",
    "    temp = SimpleImputer(verbose=1, strategy='median').fit_transform(df)\n",
    "    ## convert back to pandas\n",
    "    df = pd.DataFrame(temp, columns=df.columns, dtype='float64')\n",
    "    temp = pd.DataFrame()\n",
    "    temp['last_o2_flow'] = pd.cut(df['last_o2_flow'],\n",
    "                                 bins=[-np.inf,2,4,np.inf],\n",
    "                                 labels=['no_nc','2-4','gt4'])\n",
    "    temp['min_SPO2'] = pd.cut(df['min_SPO2'],\n",
    "                                 bins=[-np.inf,88,92,np.inf],\n",
    "                                 labels=['lt88','88-92','gt92'])\n",
    "    temp['last_RR'] = pd.cut(df['last_RR'],\n",
    "                                 bins=[-np.inf,22,28,np.inf],\n",
    "                                 labels=['lt22','22-28','gt28'])\n",
    "    # round(2*OR) - 2\n",
    "    temp['qcsi'] = 0\n",
    "    temp.loc[temp['last_o2_flow']=='2-4','qcsi'] = 4 + temp.loc[temp['last_o2_flow']=='2-4','qcsi']\n",
    "    temp.loc[temp['last_o2_flow']=='gt4','qcsi'] = 5 + temp.loc[temp['last_o2_flow']=='gt4','qcsi']\n",
    "    temp.loc[temp['min_SPO2']=='lt88','qcsi'] = 5 + temp.loc[temp['min_SPO2']=='lt88','qcsi']\n",
    "    temp.loc[temp['min_SPO2']=='88-92','qcsi'] = 2 + temp.loc[temp['min_SPO2']=='88-92','qcsi']\n",
    "    temp.loc[temp['last_RR']=='22-28','qcsi'] = 1 + temp.loc[temp['last_RR']=='22-28','qcsi']\n",
    "    temp.loc[temp['last_RR']=='gt28','qcsi'] = 2 + temp.loc[temp['last_RR']=='gt28','qcsi']\n",
    "    \n",
    "    return temp['qcsi'] \n",
    "\n",
    "def proper_curb65(df):\n",
    "    \"\"\"CURB-65 with consistency for qcsi.\n",
    "    \n",
    "    Now corrected for GCS < 15\n",
    "    \n",
    "    Arguments:\n",
    "        df (pd.DataFrame): can be within cv-fold\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series\n",
    "    \"\"\"\n",
    "    # impute\n",
    "    temp = SimpleImputer(verbose=1, strategy='median').fit_transform(df)\n",
    "    \n",
    "    ## convert back to pandas\n",
    "    df = pd.DataFrame(temp, columns=df.columns, dtype='float64')\n",
    "    \n",
    "    df['curb65'] = (df['last_GCS']<15).astype(int) + (df['bun']>=19).astype(int) + (df['last_RR']>=30).astype(int) + ((df['last_SBP']<90)|(df['last_DBP']<=60)).astype(int) + (df['age']>=65)\n",
    "    return df['curb65']\n",
    "\n",
    "def proper_qSOFA(df):\n",
    "    \"\"\"Calculate qSOFA score based on worst measurements.\n",
    "    \n",
    "    1-pt for each, GCS=<15, RRâ‰¥22, sBP<=100.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: with value added into col='curb65'\n",
    "    \n",
    "    Reference:\n",
    "        https://www.mdcalc.com/qsofa-quick-sofa-score-sepsis\n",
    "    \"\"\"\n",
    "    # impute\n",
    "    temp = SimpleImputer(verbose=1, strategy='median').fit_transform(df)\n",
    "    \n",
    "    ## convert back to pandas\n",
    "    df = pd.DataFrame(temp, columns=df.columns, dtype='float64')\n",
    "    df['qSOFA'] = (df['last_GCS']<15).astype(int) + (df['last_RR']>=22).astype(int) + (df['last_SBP']<=100)\n",
    "    return df['qSOFA']\n",
    "\n",
    "def pp_X(df):\n",
    "    min_feat = ['min_SPO2','last_o2_flow','last_RR','bun',\n",
    "                'ast','age','last_SBP',\n",
    "                'glucose',\n",
    "                'WBC','PROCAL','FERRITIN','CRP',\n",
    "                'creatinine','chloride','alt']\n",
    "    if False:\n",
    "        df.loc[df['ox_status240_ROOM_AIR']==1,'last_o2_flow'] = 0 \n",
    "    df = df.loc[:,min_feat]\n",
    "    return df\n",
    "\n",
    "def pp_qcsi(df):\n",
    "    min_feat = ['min_SPO2','last_o2_flow','last_RR']\n",
    "    if True:\n",
    "        df.loc[df['ox_status240_ROOM_AIR']==1,'last_o2_flow'] = 0 \n",
    "    df = df.loc[:,min_feat]\n",
    "    return df\n",
    "\n",
    "def pp_cci(df):\n",
    "    # impute\n",
    "    temp = SimpleImputer(verbose=1, strategy='median').fit_transform(df)\n",
    "    \n",
    "    ## convert back to pandas\n",
    "    df = pd.DataFrame(temp, columns=df.columns, dtype='float64')\n",
    "    \n",
    "    return df['mrtlt_scr']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "curb65redo LR results\n",
      "---------------------------------\n",
      "Accuracy:          0.4708%\n",
      "Sensitivity:       0.8485\n",
      "Specificity:       0.2222\n",
      "AU-ROC:            0.5015\n",
      "AU-PRC:            0.1793\n",
      "Average-precision: 0.1503\n",
      "Brier score:       0.1187\n",
      "F1-score:          0.1911\n",
      "\n",
      "qSOFAredo LR results\n",
      "---------------------------------\n",
      "Accuracy:          0.8333%\n",
      "Sensitivity:       0.4848\n",
      "Specificity:       0.7005\n",
      "AU-ROC:            0.5919\n",
      "AU-PRC:            0.2185\n",
      "Average-precision: 0.1937\n",
      "Brier score:       0.1166\n",
      "F1-score:          0.0909\n",
      "\n",
      "qCSIredo LR results\n",
      "---------------------------------\n",
      "Accuracy:          0.8208%\n",
      "Sensitivity:       0.7879\n",
      "Specificity:       0.7778\n",
      "AU-ROC:            0.8114\n",
      "AU-PRC:            0.4633\n",
      "Average-precision: 0.4299\n",
      "Brier score:       0.0975\n",
      "F1-score:          0.4941\n",
      "\n",
      "CSIredo XGB results\n",
      "---------------------------------\n",
      "Accuracy:          0.7750%\n",
      "Sensitivity:       0.7273\n",
      "Specificity:       0.7874\n",
      "AU-ROC:            0.7618\n",
      "AU-PRC:            0.4005\n",
      "Average-precision: 0.4130\n",
      "Brier score:       0.2509\n",
      "F1-score:          0.4600\n",
      "\n",
      "cci LR results\n",
      "---------------------------------\n",
      "Accuracy:          0.3583%\n",
      "Sensitivity:       0.9394\n",
      "Specificity:       0.2560\n",
      "AU-ROC:            0.6065\n",
      "AU-PRC:            0.1753\n",
      "Average-precision: 0.1852\n",
      "Brier score:       0.1184\n",
      "F1-score:          0.2804\n"
     ]
    }
   ],
   "source": [
    "models = ['curb65redo','qSOFAredo','qCSIredo','CSIredo','cci']\n",
    "methods = ['LR','LR','LR','XGB','LR']\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for model_name,method in zip(models,methods):\n",
    "    \n",
    "    model_pkl = glob.glob(os.path.join(pdfp,'{}_{}iter*.pkl'.format(model_name,method)))[0]\n",
    "    model = pickle.load(open(model_pkl, \"rb\"))   \n",
    "    \n",
    "    if method=='XGB':\n",
    "        dtest = xgb.DMatrix(pp_X(X_test), label=y_test)\n",
    "        p1 = model.predict(dtest, ntree_limit=model.best_iteration)\n",
    "        short_name = 'CSI'\n",
    "    elif method=='LR' and 'qCSI' in model_name:\n",
    "        p1 = model.predict_proba(qcsi(pp_qcsi(X_test)).to_numpy().reshape(-1,1))[:,1]\n",
    "        short_name = 'qCSI'\n",
    "    elif method=='LR' and 'qSOFA' in model_name:\n",
    "        p1 = model.predict_proba(proper_qSOFA(X_test).to_numpy().reshape(-1,1))[:,1]\n",
    "        short_name = 'qSOFA'\n",
    "    elif method=='LR' and 'curb65' in model_name:\n",
    "        p1 = model.predict_proba(proper_curb65(X_test).to_numpy().reshape(-1,1))[:,1]\n",
    "        short_name = 'CURB-65'\n",
    "    elif method=='LR' and 'cci' in model_name:\n",
    "        p1 = model.predict_proba(pp_cci(X_test_cci).to_numpy().reshape(-1,1))[:,1]\n",
    "        short_name = 'Elixhauser'\n",
    "    \n",
    "    # metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, p1)\n",
    "    optimal_idx = np.argmax(tpr-fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_pred = (p1>optimal_threshold).astype(int)\n",
    "    precision,recall,_ = metrics.precision_recall_curve(y_test, p1)\n",
    "    auprc = metrics.auc(recall, precision)\n",
    "    auroc = metrics.roc_auc_score(y_test,p1)\n",
    "    ap = metrics.average_precision_score(y_test,p1)\n",
    "    bs = metrics.brier_score_loss(y_test,p1)\n",
    "    f1 = metrics.f1_score(y_test,optimal_pred)\n",
    "    acc = metrics.accuracy_score(y_test,optimal_pred)\n",
    "\n",
    "    # results\n",
    "    print('\\n{} {} results'.format(model_name, method))\n",
    "    print('---------------------------------')\n",
    "    print('Accuracy:          {:.4f}%'.format(acc))\n",
    "    print('Sensitivity:       {:.4f}'.format(tpr[optimal_idx]))\n",
    "    print('Specificity:       {:.4f}'.format(1-fpr[optimal_idx]))\n",
    "    print('AU-ROC:            {:.4f}'.format(auroc))\n",
    "    print('AU-PRC:            {:.4f}'.format(auprc))\n",
    "    print('Average-precision: {:.4f}'.format(ap))\n",
    "    print('Brier score:       {:.4f}'.format(bs))\n",
    "    print('F1-score:          {:.4f}'.format(f1))\n",
    "    \n",
    "    dt = pd.DataFrame({'':short_name,\n",
    "                       'AU-ROC':auroc,\n",
    "                       'Accuracy':acc,\n",
    "                       'Sensitivity':tpr[optimal_idx],\n",
    "                       'Specificity':1-fpr[optimal_idx],\n",
    "                       'AU-PRC':auprc,\n",
    "                       'Brier score':bs,\n",
    "                       'F1':f1,\n",
    "                       'Average Precision':ap},index=[short_name])\n",
    "    results = results.append(dt, ignore_index=True)\n",
    "results.to_csv(os.path.join(pdfp,'test_eval.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(os.path.join(pdfp,'test_eval.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
